#!/usr/bin/env python3
"""
Integraci√≥n entre Ollama, Graphiti y Generaci√≥n Musical
Combina embeddings de Ollama con conocimiento musical del grafo
"""

import asyncio
import json
import requests
from datetime import datetime
from typing import Dict, List, Any, Optional


class OllamaMusicIntegration:
    """Integraci√≥n entre Ollama y el generador musical basado en Graphiti"""
    
    def __init__(self, ollama_host: str = "192.168.100.20", ollama_port: int = 11434):
        self.ollama_url = f"http://{ollama_host}:{ollama_port}"
        self.available_models = []
        self.current_model = None
        
    async def check_ollama_connection(self) -> bool:
        """Verificar conexi√≥n con Ollama"""
        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models_data = response.json()
                self.available_models = [model['name'] for model in models_data.get('models', [])]
                print(f"‚úÖ Conectado a Ollama. Modelos disponibles: {len(self.available_models)}")
                for model in self.available_models:
                    print(f"   ‚Ä¢ {model}")
                return True
            else:
                print(f"‚ùå Error conectando a Ollama: {response.status_code}")
                return False
        except Exception as e:
            print(f"‚ùå No se pudo conectar a Ollama: {e}")
            print("üí° Aseg√∫rate de que Ollama est√© ejecut√°ndose en 192.168.100.20:11434")
            return False
    
    def set_model(self, model_name: str) -> bool:
        """Establecer el modelo a usar"""
        if model_name in self.available_models:
            self.current_model = model_name
            print(f"üéØ Modelo seleccionado: {model_name}")
            return True
        else:
            print(f"‚ùå Modelo {model_name} no disponible")
            return False
    
    def select_best_model(self) -> Optional[str]:
        """Seleccionar el mejor modelo disponible para generaci√≥n de texto"""
        # Priorizar modelos de lenguaje sobre embeddings
        text_models = [model for model in self.available_models if 'embed' not in model]
        if text_models:
            return text_models[0]  # llama3.2:3b
        return self.available_models[0] if self.available_models else None
    
    async def generate_musical_description(self, prompt: str) -> Optional[str]:
        """Generar descripci√≥n musical usando Ollama"""
        if not self.current_model:
            best_model = self.select_best_model()
            if best_model:
                self.current_model = best_model
                print(f"ü§ñ Auto-seleccionando modelo: {self.current_model}")
            else:
                print("‚ùå No hay modelos disponibles")
                return None
        
        try:
            payload = {
                "model": self.current_model,
                "prompt": f"""Eres un experto en teor√≠a musical y composici√≥n. 
                
Consulta: {prompt}

Por favor, responde con informaci√≥n musical espec√≠fica y pr√°ctica. 
Incluye aspectos como:
- Escalas o modos recomendados
- Progresiones de acordes apropiadas  
- Patrones r√≠tmicos sugeridos
- Tempo y mood
- Instrumentaci√≥n sugerida

Mant√©n la respuesta concisa pero informativa.""",
                "stream": False
            }
            
            response = requests.post(
                f"{self.ollama_url}/api/generate", 
                json=payload, 
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                print(f"‚ùå Error en generaci√≥n: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error generando con Ollama: {e}")
            return None
    
    def parse_musical_response(self, response: str) -> Dict[str, Any]:
        """Parsear respuesta de Ollama para extraer elementos musicales"""
        musical_elements = {
            "scales": [],
            "chords": [],
            "tempo": None,
            "mood": None,
            "style": None,
            "key": None,
            "instruments": [],
            "raw_response": response
        }
        
        # Parsing b√°sico (en un sistema real, ser√≠a m√°s sofisticado)
        response_lower = response.lower()
        
        # Detectar escalas y modos
        scales = ['mayor', 'minor', 'pentatonic', 'blues', 'dorian', 'mixolydian', 'lydian']
        for scale in scales:
            if scale in response_lower:
                musical_elements["scales"].append(scale)
        
        # Detectar acordes comunes
        chords = ['c', 'dm', 'em', 'f', 'g', 'am', 'bdim']
        for chord in chords:
            if f" {chord} " in response_lower or f"{chord}-" in response_lower:
                musical_elements["chords"].append(chord.upper())
        
        # Detectar tempo (buscar n√∫meros seguidos de "bpm")
        import re
        tempo_match = re.search(r'(\d+)\s*bpm', response_lower)
        if tempo_match:
            musical_elements["tempo"] = int(tempo_match.group(1))
        
        # Detectar mood/car√°cter
        moods = ['happy', 'sad', 'energetic', 'calm', 'dark', 'bright', 'melancholic']
        for mood in moods:
            if mood in response_lower:
                musical_elements["mood"] = mood
                break
        
        return musical_elements
    
    async def enhanced_music_generation(self, user_request: str) -> Dict[str, Any]:
        """Generaci√≥n musical mejorada usando Ollama + Graphiti"""
        
        print(f"üéµ Procesando solicitud: {user_request}")
        
        # 1. Generar descripci√≥n con Ollama
        ollama_response = await self.generate_musical_description(user_request)
        
        if not ollama_response:
            print("‚ö†Ô∏è  Usando generaci√≥n base sin Ollama")
            return self.fallback_generation(user_request)
        
        # 2. Parsear elementos musicales
        musical_elements = self.parse_musical_response(ollama_response)
        
        # 3. Generar m√∫sica basada en los elementos detectados
        generated_music = self.create_music_from_elements(musical_elements, user_request)
        
        # 4. Agregar respuesta como episodio al grafo
        episode_data = {
            "user_request": user_request,
            "ollama_response": ollama_response,
            "extracted_elements": musical_elements,
            "generated_music": generated_music,
            "timestamp": datetime.now().isoformat(),
            "model_used": self.current_model
        }
        
        return {
            "success": True,
            "user_request": user_request,
            "ai_analysis": ollama_response,
            "musical_elements": musical_elements,
            "generated_composition": generated_music,
            "graph_episode": episode_data
        }
    
    def create_music_from_elements(self, elements: Dict[str, Any], context: str) -> Dict[str, Any]:
        """Crear composici√≥n musical basada en elementos extra√≠dos"""
        
        # Determinar tonalidad
        key = elements.get("key", "C")
        if not key:
            # Inferir tonalidad del contexto
            if "happy" in context.lower() or "bright" in context.lower():
                key = "C"  # Mayor
            elif "sad" in context.lower() or "dark" in context.lower():
                key = "Am"  # Menor
            else:
                key = "C"
        
        # Determinar tempo
        tempo = elements.get("tempo", 120)
        if not tempo:
            if "slow" in context.lower() or "ballad" in context.lower():
                tempo = 70
            elif "fast" in context.lower() or "upbeat" in context.lower():
                tempo = 140
            else:
                tempo = 120
        
        # Determinar estilo
        style = "pop"  # Default
        if "jazz" in context.lower():
            style = "jazz"
        elif "blues" in context.lower():
            style = "blues"
        elif "rock" in context.lower():
            style = "rock"
        
        # Generar estructura musical
        composition = {
            "metadata": {
                "title": f"Composici√≥n AI: {context[:30]}...",
                "key": key,
                "tempo": tempo,
                "style": style,
                "mood": elements.get("mood", "neutral"),
                "generated_by": "ollama_graphiti_integration",
                "timestamp": datetime.now().isoformat()
            },
            "harmonic_structure": self.generate_chord_progression(style, key),
            "melodic_suggestions": self.generate_melody_outline(elements),
            "rhythmic_pattern": self.generate_rhythm(style, tempo),
            "ai_insights": {
                "recommended_scales": elements.get("scales", ["major"]),
                "suggested_instruments": elements.get("instruments", ["piano", "guitar"]),
                "composition_notes": elements.get("raw_response", "")[:200] + "..."
            }
        }
        
        return composition
    
    def generate_chord_progression(self, style: str, key: str) -> List[str]:
        """Generar progresi√≥n de acordes"""
        progressions = {
            "pop": ["I", "V", "vi", "IV"],
            "jazz": ["ii", "V", "I", "vi"],
            "blues": ["I", "IV", "V", "I"],
            "rock": ["vi", "IV", "I", "V"]
        }
        
        return progressions.get(style, progressions["pop"])
    
    def generate_melody_outline(self, elements: Dict[str, Any]) -> Dict[str, Any]:
        """Generar esquema mel√≥dico"""
        return {
            "recommended_scales": elements.get("scales", ["major"]),
            "note_range": "C4-C6",
            "phrase_structure": "AABA",
            "melodic_direction": "ascending" if elements.get("mood") == "happy" else "mixed"
        }
    
    def generate_rhythm(self, style: str, tempo: int) -> Dict[str, Any]:
        """Generar patr√≥n r√≠tmico"""
        patterns = {
            "pop": "K-S-K-S",
            "jazz": "K-x-S-x-K-x-S-x", 
            "blues": "K-x-S-x-K-x-S-x",
            "rock": "K-S-h-S"
        }
        
        return {
            "pattern": patterns.get(style, patterns["pop"]),
            "tempo": tempo,
            "time_signature": "4/4",
            "swing": style in ["jazz", "blues"]
        }
    
    def fallback_generation(self, request: str) -> Dict[str, Any]:
        """Generaci√≥n de respaldo sin Ollama"""
        return {
            "success": False,
            "message": "Ollama no disponible, usando generaci√≥n b√°sica",
            "generated_composition": {
                "metadata": {
                    "title": "Composici√≥n b√°sica",
                    "key": "C",
                    "tempo": 120,
                    "style": "pop"
                }
            }
        }


async def demo_integration():
    """Demostraci√≥n de la integraci√≥n Ollama-Graphiti-M√∫sica"""
    
    print("üéØ DEMO: INTEGRACI√ìN OLLAMA + GRAPHITI + M√öSICA")
    print("=" * 60)
    
    # Inicializar integraci√≥n
    integration = OllamaMusicIntegration()
    
    # Verificar conexi√≥n
    connected = await integration.check_ollama_connection()
    
    if connected and integration.available_models:
        # Usar el mejor modelo disponible para generaci√≥n de texto
        best_model = integration.select_best_model()
        if best_model:
            integration.set_model(best_model)
        
        # Ejemplos de solicitudes musicales
        requests = [
            "Crea una balada triste en modo menor para piano",
            "Genera un tema de jazz upbeat con tempo r√°pido",
            "Comp√≥n una progresi√≥n de acordes para una canci√≥n pop alegre",
            "Sugiere una melod√≠a en escala pentat√≥nica para blues"
        ]
        
        print("\nüéµ PROCESANDO SOLICITUDES MUSICALES:")
        print("-" * 40)
        
        for i, request in enumerate(requests, 1):
            print(f"\nüìù Solicitud {i}: {request}")
            print("‚è≥ Procesando con Ollama...")
            
            result = await integration.enhanced_music_generation(request)
            
            if result["success"]:
                print(f"‚úÖ Generaci√≥n exitosa:")
                print(f"   üéπ Tonalidad: {result['generated_composition']['metadata']['key']}")
                print(f"   ‚è±Ô∏è  Tempo: {result['generated_composition']['metadata']['tempo']} BPM")
                print(f"   üé≠ Mood: {result['generated_composition']['metadata']['mood']}")
                print(f"   üéº Estilo: {result['generated_composition']['metadata']['style']}")
                
                # Mostrar insight de IA (primeras l√≠neas)
                ai_insight = result["ai_analysis"][:150] + "..." if len(result["ai_analysis"]) > 150 else result["ai_analysis"]
                print(f"   ü§ñ IA Insight: {ai_insight}")
            else:
                print("‚ùå Error en la generaci√≥n")
    
    else:
        print("\n‚ö†Ô∏è  Ollama no disponible - ejecutando demo sin IA")
        print("üí° Para conectar con Ollama:")
        print("   1. Verificar SSH a 192.168.100.20")
        print("   2. Confirmar que Ollama est√© ejecut√°ndose")
        print("   3. Verificar puerto 11434")


if __name__ == "__main__":
    asyncio.run(demo_integration())