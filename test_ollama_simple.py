#!/usr/bin/env python3
"""
Test simple de conexi√≥n Ollama para generaci√≥n musical
"""

import requests
import json

def test_ollama_connection():
    """Test b√°sico de Ollama"""
    
    print("üîç Probando conexi√≥n a Ollama...")
    
    ollama_url = "http://192.168.100.20:11434"
    
    try:
        # Obtener modelos disponibles
        response = requests.get(f"{ollama_url}/api/tags", timeout=5)
        
        if response.status_code == 200:
            models = response.json()
            print("‚úÖ Conectado a Ollama!")
            print(f"üìä Modelos disponibles:")
            
            for model in models.get('models', []):
                print(f"   ‚Ä¢ {model['name']} ({model.get('size', 'unknown size')})")
            
            # Encontrar modelo de texto
            text_models = [m['name'] for m in models.get('models', []) if 'embed' not in m['name']]
            
            if text_models:
                model_to_use = text_models[0]
                print(f"\nüéØ Usando modelo: {model_to_use}")
                
                # Test de generaci√≥n simple
                print("üß™ Probando generaci√≥n musical simple...")
                
                payload = {
                    "model": model_to_use,
                    "prompt": "Suggest a simple chord progression for a happy pop song in C major. Keep it very short.",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "num_predict": 100  # Limitar respuesta
                    }
                }
                
                print("‚è≥ Generando respuesta...")
                response = requests.post(
                    f"{ollama_url}/api/generate",
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    result = response.json()
                    ai_response = result.get('response', '').strip()
                    
                    print("‚úÖ Generaci√≥n exitosa!")
                    print(f"üéµ Respuesta de IA:")
                    print(f"   {ai_response}")
                    
                    # Crear episodio musical para Graphiti
                    musical_episode = {
                        "name": "Progresi√≥n de Acordes Pop Generada por IA",
                        "content": ai_response,
                        "model_used": model_to_use,
                        "query": "chord progression for happy pop song",
                        "timestamp": "2025-07-23"
                    }
                    
                    print(f"\nüìä Episodio musical creado:")
                    print(f"   T√≠tulo: {musical_episode['name']}")
                    print(f"   Modelo: {musical_episode['model_used']}")
                    print(f"   Contenido: {musical_episode['content'][:100]}...")
                    
                    return musical_episode
                    
                else:
                    print(f"‚ùå Error en generaci√≥n: {response.status_code}")
                    print(f"Response: {response.text}")
                    
            else:
                print("‚ùå No hay modelos de texto disponibles")
                
        else:
            print(f"‚ùå Error conectando: {response.status_code}")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        
    return None

if __name__ == "__main__":
    print("üéµ TEST SIMPLE OLLAMA + M√öSICA")
    print("=" * 40)
    
    episode = test_ollama_connection()
    
    if episode:
        print(f"\n‚úÖ TEST EXITOSO")
        print("üîó Listo para integrar con Graphiti")
    else:
        print(f"\n‚ùå TEST FALLIDO")
        print("üîß Revisar configuraci√≥n de Ollama")