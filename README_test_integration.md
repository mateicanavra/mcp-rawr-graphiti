# Gu√≠a de Integraci√≥n Ollama + Graphiti

Esta gu√≠a documenta el script `test_integration.py` que demuestra la integraci√≥n entre el sistema de IA Ollama (ejecut√°ndose en VM) y el servidor MCP de Graphiti.

## üìã Resumen de la Integraci√≥n

El script realiza las siguientes operaciones:
1. **Conecta con Ollama** en la VM `192.168.100.20:11434`
2. **Hace preguntas** al modelo `llama3.2:3b`
3. **Guarda las respuestas** como episodios en Graphiti
4. **Busca informaci√≥n** en el grafo de conocimiento de Graphiti

## üõ†Ô∏è Componentes del Sistema

### Ollama (VM: 192.168.100.20)
- **Puerto**: 11434
- **Modelo**: llama3.2:3b
- **Endpoint**: `/api/generate`
- **Funci√≥n**: Procesamiento de lenguaje natural

### Graphiti MCP Server (Local)
- **Puerto**: 8000
- **Endpoint**: `/messages/`
- **Funci√≥n**: Gesti√≥n de memoria en grafo de conocimiento
- **Protocolo**: Model Context Protocol (MCP)

## üìÅ Estructura del Script

### Configuraci√≥n
```python
OLLAMA_URL = "http://192.168.100.20:11434/api/generate"
OLLAMA_MODEL = "llama3.2:3b"
GRAPHITI_MCP_URL = "http://localhost:8000/messages/"
SESSION_ID = "5b6d90707c01457593e5610fc2129c66"
```

### Funciones Principales

#### `ask_ollama(prompt: str) -> str`
- Env√≠a prompts al modelo de IA en la VM
- Maneja timeouts y errores de conexi√≥n
- Retorna la respuesta generada por el modelo

#### `add_episode_to_graphiti(name, content, group_id)`
- Crea episodios en el grafo de conocimiento
- Usa protocolo MCP para comunicarse con Graphiti
- Organiza informaci√≥n por `group_id`

#### `search_in_graphiti(query, group_id)`
- Busca nodos relacionados en el grafo
- Usa b√∫squeda sem√°ntica
- Filtra por grupos de informaci√≥n

## üöÄ Flujo de Ejecuci√≥n

1. **Verificaci√≥n de Conexiones**
   - Prueba conexi√≥n con Ollama
   - Verifica disponibilidad de Graphiti MCP

2. **Generaci√≥n de Contenido**
   - Env√≠a pregunta a Ollama: "¬øQu√© es un sistema de grafos de conocimiento?"
   - Recibe respuesta del modelo IA

3. **Almacenamiento en Graphiti**
   - Crea episodio con pregunta y respuesta
   - Asigna timestamp y metadatos
   - Guarda en grupo `test_integration`

4. **Procesamiento**
   - Espera 10 segundos para procesamiento as√≠ncrono
   - Permite que Graphiti construya el grafo

5. **B√∫squeda y Validaci√≥n**
   - Busca t√©rminos relacionados: "grafos conocimiento"
   - Verifica que la informaci√≥n est√© indexada

6. **Segunda Iteraci√≥n**
   - Pregunta espec√≠fica sobre Neo4j
   - Repite el ciclo de almacenamiento

## üìä Resultados Esperados

### Exitoso ‚úÖ
```
Resultado de Graphiti: Accepted
B√∫squeda 'grafos conocimiento': Accepted
```

### Con Errores ‚ùå
```
Could not find session
Error al llamar a Ollama: [detalles]
Error al conectar con Graphiti: [detalles]
```

## üîß Requisitos Previos

### VM Ollama (192.168.100.20)
- [x] Servidor Ollama corriendo en puerto 11434
- [x] Modelo `llama3.2:3b` descargado
- [x] Acceso de red desde la m√°quina local

### Local Graphiti
- [x] Servidor MCP corriendo en puerto 8000
- [x] Base de datos Neo4j configurada
- [x] Sesi√≥n v√°lida obtenida desde `/sse`

### Python Dependencies
```bash
pip install requests
```

## üìù Logs de Ejemplo

```
=== PRUEBA DE INTEGRACI√ìN OLLAMA + GRAPHITI ===
Fecha: 2025-07-23 20:26:15.053001
Ollama URL: http://192.168.100.20:11434/api/generate
Modelo: llama3.2:3b
Graphiti MCP URL: http://localhost:8000/messages/

1. Probando conexi√≥n con Ollama...
Pregunta: ¬øQu√© es un sistema de grafos de conocimiento?
Respuesta: ¬°Excelente pregunta! Un sistema de grafos de conocimiento...

2. Guardando respuesta en Graphiti...
Resultado de Graphiti: Accepted

3. Esperando procesamiento...

4. Buscando en Graphiti...
B√∫squeda 'grafos conocimiento': Accepted

5. Segunda prueba con pregunta espec√≠fica...
Pregunta espec√≠fica: ¬øCu√°les son las ventajas de usar Neo4j...
Respuesta: **Ventajas de usar Neo4j para almacenar grafos de conocimiento**...
Segundo episodio guardado: Accepted

=== PRUEBA COMPLETADA ===
```

## üéØ Casos de Uso

### 1. Investigaci√≥n Asistida por IA
- Hacer preguntas complejas a Ollama
- Almacenar respuestas estructuradas en Graphiti
- Buscar informaci√≥n relacionada posteriormente

### 2. Construcci√≥n de Base de Conocimiento
- Generar contenido sobre temas espec√≠ficos
- Crear redes de conceptos interconectados
- Facilitar descubrimiento de relaciones

### 3. Sistema de Memoria Persistente
- Mantener historial de consultas
- Evolucionar conocimiento a trav√©s del tiempo
- Recuperar contexto de conversaciones previas

## üîç Verificaci√≥n Manual

### Comprobar Ollama
```bash
curl -X GET "http://192.168.100.20:11434/api/tags"
```

### Obtener Nueva Sesi√≥n Graphiti
```bash
curl http://localhost:8000/sse
```

### Verificar Estado del Servidor
```bash
curl -X POST "http://localhost:8000/messages/?session_id=<ID>" \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc": "2.0", "method": "resource", "params": {"uri": "http://graphiti/status"}, "id": 1}'
```

## üìà M√©tricas de Rendimiento

| Operaci√≥n | Tiempo Promedio | Timeout |
|-----------|----------------|---------|
| Consulta Ollama | 30-60 segundos | 90s |
| Add Episode | <1 segundo | 30s |
| Search Nodes | <1 segundo | 30s |
| Procesamiento BG | 5-15 segundos | N/A |

## üö® Troubleshooting

### Error: "Could not find session"
- Obtener nueva sesi√≥n desde `/sse`
- Actualizar `SESSION_ID` en el script

### Error: "model 'X' not found"
- Verificar modelos disponibles en Ollama
- Descargar modelo requerido: `ollama pull llama3.2:3b`

### Timeout en Ollama
- Verificar conectividad de red con la VM
- Aumentar timeout en la funci√≥n `ask_ollama`

### "Accepted" sin resultados
- Normal - Graphiti procesa episodios as√≠ncronamente
- Esperar m√°s tiempo antes de buscar
- Verificar logs del servidor Graphiti